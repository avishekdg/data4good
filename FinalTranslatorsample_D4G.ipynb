{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc1dca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required modules\n",
    "import json\n",
    "import csv\n",
    "import requests\n",
    "import time\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.ai.textanalytics import TextAnalyticsApiVersion\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "\n",
    "# Define the Azure Text Analytics and Translator credentials\n",
    "text_analytics_key = \"0a4065d87f7a453498faa85ad8c47bf0\"\n",
    "text_analytics_endpoint = \"https://azureapi.cognitiveservices.azure.com/\"\n",
    "translator_key = \"600a4d74fd7c4962a6111fa03c4d4a7e\"\n",
    "translator_endpoint = \"https://api.cognitive.microsofttranslator.com/\"\n",
    "\n",
    "# Create the Text Analytics and Translator clients\n",
    "text_analytics_client = TextAnalyticsClient(\n",
    "    endpoint=text_analytics_endpoint,\n",
    "    credential=AzureKeyCredential(text_analytics_key),\n",
    "    #api_version=TextAnalyticsApiVersion.V3_0_0 # Use the latest preview version for Text Analytics for health\n",
    ")\n",
    "translator_client = requests.Session()\n",
    "translator_client.headers.update({\n",
    "    'Ocp-Apim-Subscription-Key': translator_key,\n",
    "    'Ocp-Apim-Subscription-Region': \"eastus2\",\n",
    "    'Content-type': 'application/json'\n",
    "})\n",
    "\n",
    "# Define the input and output files\n",
    "input_file = \"input.json\"\n",
    "output_file = \"output.csv\"\n",
    "\n",
    "# Define the rate limit for the free tier (5 requests per second)\n",
    "rate_limit = 5\n",
    "\n",
    "# Define a helper function to translate a text to English\n",
    "def translate_to_english(text):\n",
    "    # Construct the request body\n",
    "    body = [{\n",
    "        'text': text\n",
    "    }]\n",
    "    # Send the request to the Translator service\n",
    "    response = translator_client.post(translator_endpoint + '/translate?api-version=3.0&to=en', json=body)\n",
    "    # Parse the response\n",
    "    result = response.json()\n",
    "    # Return the translated text\n",
    "    return result[0]['translations'][0]['text']\n",
    "\n",
    "# Open the input file and load the JSON data\n",
    "with open(input_file, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Open the output file and create a CSV writer\n",
    "with open(output_file, 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # Write the header row\n",
    "    writer.writerow(['id', 'text', 'language', 'key_phrases'])\n",
    "\n",
    "    # Define the list of ids to read\n",
    "    ids = [76, 157, 127, 201, 478]\n",
    "\n",
    "    # Loop through the ids\n",
    "    for id in ids:\n",
    "        # Get the text from the data using the id as the key\n",
    "        text = data[str(id)]\n",
    "\n",
    "        # Detect the language of the text\n",
    "        try:\n",
    "            response = text_analytics_client.detect_language(documents=[text])\n",
    "            language = response[0].primary_language.name\n",
    "        except HttpResponseError as e:\n",
    "            print(f'Error detecting language for id {id}: {e}')\n",
    "            language = 'Unknown'\n",
    "\n",
    "        # If the language is not English, translate the text to English\n",
    "        if language != 'English':\n",
    "            text = translate_to_english(text)\n",
    "\n",
    "        # Extract the key phrases from the text\n",
    "        try:\n",
    "            response = text_analytics_client.extract_key_phrases(documents=[text])\n",
    "            key_phrases = ', '.join(response[0].key_phrases)\n",
    "        except HttpResponseError as e:\n",
    "            print(f'Error extracting key phrases for id {id}: {e}')\n",
    "            key_phrases = ''\n",
    "\n",
    "        # Write the output row\n",
    "        writer.writerow([id, text, language, key_phrases])\n",
    "\n",
    "        # Wait for 1/rate_limit seconds to avoid exceeding the free tier limit\n",
    "        time.sleep(1/rate_limit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcff25f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
