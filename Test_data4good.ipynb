{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2863884d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-cognitiveservices-language-textanalytics\n",
      "  Downloading azure_cognitiveservices_language_textanalytics-0.2.1-py2.py3-none-any.whl (44 kB)\n",
      "     ---------------------------------------- 0.0/44.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 44.8/44.8 kB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas in c:\\users\\avish\\anaconda3\\lib\\site-packages (1.5.3)\n",
      "Collecting msrest>=0.6.21 (from azure-cognitiveservices-language-textanalytics)\n",
      "  Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
      "     ---------------------------------------- 0.0/85.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 85.4/85.4 kB 2.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: azure-common~=1.1 in c:\\users\\avish\\anaconda3\\lib\\site-packages (from azure-cognitiveservices-language-textanalytics) (1.1.28)\n",
      "Collecting azure-mgmt-core<2.0.0,>=1.2.0 (from azure-cognitiveservices-language-textanalytics)\n",
      "  Downloading azure_mgmt_core-1.4.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\avish\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\avish\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\avish\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.26.2 in c:\\users\\avish\\anaconda3\\lib\\site-packages (from azure-mgmt-core<2.0.0,>=1.2.0->azure-cognitiveservices-language-textanalytics) (1.29.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\avish\\anaconda3\\lib\\site-packages (from msrest>=0.6.21->azure-cognitiveservices-language-textanalytics) (2023.7.22)\n",
      "Requirement already satisfied: isodate>=0.6.0 in c:\\users\\avish\\anaconda3\\lib\\site-packages (from msrest>=0.6.21->azure-cognitiveservices-language-textanalytics) (0.6.1)\n",
      "Collecting requests-oauthlib>=0.5.0 (from msrest>=0.6.21->azure-cognitiveservices-language-textanalytics)\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: requests~=2.16 in c:\\users\\avish\\anaconda3\\lib\\site-packages (from msrest>=0.6.21->azure-cognitiveservices-language-textanalytics) (2.31.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\avish\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\avish\\anaconda3\\lib\\site-packages (from azure-core<2.0.0,>=1.26.2->azure-mgmt-core<2.0.0,>=1.2.0->azure-cognitiveservices-language-textanalytics) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\avish\\anaconda3\\lib\\site-packages (from requests~=2.16->msrest>=0.6.21->azure-cognitiveservices-language-textanalytics) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\avish\\anaconda3\\lib\\site-packages (from requests~=2.16->msrest>=0.6.21->azure-cognitiveservices-language-textanalytics) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\avish\\anaconda3\\lib\\site-packages (from requests~=2.16->msrest>=0.6.21->azure-cognitiveservices-language-textanalytics) (1.26.16)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-cognitiveservices-language-textanalytics)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     ---------------------------------------- 0.0/151.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 151.7/151.7 kB ? eta 0:00:00\n",
      "Installing collected packages: oauthlib, requests-oauthlib, msrest, azure-mgmt-core, azure-cognitiveservices-language-textanalytics\n",
      "Successfully installed azure-cognitiveservices-language-textanalytics-0.2.1 azure-mgmt-core-1.4.0 msrest-0.7.1 oauthlib-3.2.2 requests-oauthlib-1.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install azure-cognitiveservices-language-textanalytics pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53dc8330",
   "metadata": {},
   "outputs": [
    {
     "ename": "ErrorResponseException",
     "evalue": "Operation returned an invalid status code 'Access Denied'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mErrorResponseException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 49\u001b[0m\n\u001b[0;32m     46\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(request_interval)\n\u001b[0;32m     47\u001b[0m     characters_translated \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# Reset characters translated\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m translated_text \u001b[38;5;241m=\u001b[39m detect_and_translate(text)\n\u001b[0;32m     50\u001b[0m characters_translated \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m text_length\n\u001b[0;32m     52\u001b[0m translated_data\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSerial no\u001b[39m\u001b[38;5;124m'\u001b[39m: serial_no, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m: translated_text})\n",
      "Cell \u001b[1;32mIn[19], line 16\u001b[0m, in \u001b[0;36mdetect_and_translate\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetect_and_translate\u001b[39m(text):\n\u001b[1;32m---> 16\u001b[0m     response \u001b[38;5;241m=\u001b[39m translator_client\u001b[38;5;241m.\u001b[39mdetect_language(text)\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mprimary_language\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     18\u001b[0m         translation \u001b[38;5;241m=\u001b[39m translator_client\u001b[38;5;241m.\u001b[39mtranslate(text, target_language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\azure\\cognitiveservices\\language\\textanalytics\\text_analytics_client.py:136\u001b[0m, in \u001b[0;36mTextAnalyticsClient.detect_language\u001b[1;34m(self, show_stats, documents, custom_headers, raw, **operation_config)\u001b[0m\n\u001b[0;32m    133\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(request, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moperation_config)\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m200\u001b[39m]:\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m models\u001b[38;5;241m.\u001b[39mErrorResponseException(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deserialize, response)\n\u001b[0;32m    138\u001b[0m deserialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n",
      "\u001b[1;31mErrorResponseException\u001b[0m: Operation returned an invalid status code 'Access Denied'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from azure.cognitiveservices.language.textanalytics import TextAnalyticsClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "import time\n",
    "\n",
    "# Azure Cognitive Services configuration\n",
    "subscription_key = '9e2da6a0d11c4fb28ef9b06d4cd1b2df'\n",
    "endpoint = 'https://dataforgood.cognitiveservices.azure.com/'\n",
    "location = 'useast2'  # Add your Azure Translator service location\n",
    "\n",
    "translator_client = TextAnalyticsClient(endpoint=endpoint, credentials=CognitiveServicesCredentials(subscription_key))\n",
    "\n",
    "# Function to detect language and translate\n",
    "def detect_and_translate(text):\n",
    "    response = translator_client.detect_language(text)\n",
    "    if response.primary_language.name != 'en':\n",
    "        translation = translator_client.translate(text, target_language='en')\n",
    "        return translation\n",
    "    return text\n",
    "\n",
    "# Read JSON file\n",
    "with open('transcripts.json', 'r') as json_file:\n",
    "    data = json.loads(json_file.read())\n",
    "\n",
    "# Create an empty list to store the translated data\n",
    "translated_data = []\n",
    "\n",
    "# Initialize variables for rate limiting\n",
    "characters_translated = 0\n",
    "characters_limit = 50000\n",
    "characters_per_request = 5000\n",
    "request_interval = 12  # 60 minutes / 5 requests per minute (to stay within hourly quota)\n",
    "\n",
    "# Serial numbers to process\n",
    "serial_numbers_to_process = [76, 157, 127, 201, 478]\n",
    "\n",
    "# Process each entry in the JSON file\n",
    "for serial_no, text in data.items():\n",
    "    if int(serial_no) not in serial_numbers_to_process:\n",
    "        continue  # Skip if serial number not in the list\n",
    "\n",
    "    # Check if text is in English, and if not, translate it\n",
    "    text_length = len(text)\n",
    "    if text_length + characters_translated > characters_limit:\n",
    "        time.sleep(request_interval)\n",
    "        characters_translated = 0  # Reset characters translated\n",
    "\n",
    "    translated_text = detect_and_translate(text)\n",
    "    characters_translated += text_length\n",
    "\n",
    "    translated_data.append({'Serial no': serial_no, 'text': translated_text})\n",
    "\n",
    "# Convert the translated data to a DataFrame\n",
    "df = pd.DataFrame(translated_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('translated_transcripts.csv', index=False)\n",
    "\n",
    "print(\"Translation and saving completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce85a639",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
